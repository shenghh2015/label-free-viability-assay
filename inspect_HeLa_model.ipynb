{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models: using `tf.keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from skimage import io\n",
    "import sys\n",
    "sys.path.append('create_models')\n",
    "import create_models as cm\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "## Set the which GPU to run\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'  \n",
    "\n",
    "## trained model folder\n",
    "model_folder = './trained_models/'\n",
    "\n",
    "## Load testing images\n",
    "image_dir = './images/HeLa'\t\t\t\t\t\t\t\t# image directory: save each input image as a RGB image [HxWx3], where each channel \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t# contain the same phase contrast image; normalize the values into pixel values of range: [0,255], dtype: np.uint8\n",
    "\n",
    "img_fns = os.listdir(image_dir)\n",
    "images = np.stack([io.imread(image_dir+'/{}'.format(img_fn)) for img_fn in img_fns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing ...\n",
      "<module 'tensorflow.python.keras.api._v1.keras.backend' from '/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/api/_v1/keras/backend/__init__.py'>\n",
      "<module 'tensorflow.python.keras.api._v1.keras.layers' from '/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/api/_v1/keras/layers/__init__.py'>\n",
      "<module 'tensorflow.python.keras.api._v1.keras.models' from '/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/api/_v1/keras/models/__init__.py'>\n",
      "<module 'tensorflow.python.keras.api._v1.keras.utils' from '/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/api/_v1/keras/utils/__init__.py'>\n",
      "Preprocessing done !\n"
     ]
    }
   ],
   "source": [
    "## Image preprocessing\n",
    "print('Preprocessing ...')\n",
    "backbone = 'efficientnetb3'\n",
    "preprocess_input = cm.get_preprocessing(backbone) \t## preprocessing function\n",
    "images = preprocess_input(images); \t\t\t\t\t# will scale pixels between 0 and 1 and then will normalize each channel with respect to the ImageNet dataset\n",
    "print('Preprocessing done !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def get_ax(rows=1, cols=1, size=16):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Adjust the size attribute to control how big to render images\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    fig.tight_layout()\n",
    "    SMALL_SIZE = 24\n",
    "    MEDIUM_SIZE = 24\n",
    "    BIGGER_SIZE = 24\n",
    "\n",
    "    plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "    plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "    plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "    plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "    plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0327 05:32:02.131244 139654968117056 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0327 05:32:02.132224 139654968117056 deprecation.py:573] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:507: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with distribution=normal is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`normal` is a deprecated alias for `truncated_normal`\n",
      "W0327 05:32:02.132693 139654968117056 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0327 05:32:02.137436 139654968117056 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0327 05:32:02.367465 139654968117056 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "## Load the trained model\n",
    "model=tf.keras.models.load_model(model_folder+'/HeLa-b3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Label map prediction\n",
    "start_time = time.time()\n",
    "pr_masks = model.predict(images, batch_size=1); \t## probability maps [N(num of images) x H x W x C(class)] for 0: live, 1: intermediate, 2: dead, 3: background\n",
    "pr_maps = np.argmax(pr_masks,axis=-1)   \t\t\t# predicted label map\n",
    "end_time = time.time()\n",
    "print('Average time: {:.4f} per image'.format((end_time-start_time)/len(images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "indices = [8, 21, 43, 90]  # four examples\n",
    "ax = get_ax(len(indices),4,5)\n",
    "for i, index in enumerate(indices):\n",
    "    pr_map = pr_maps[index,:,:]\n",
    "    ax[i, 0].imshow(io.imread(image_dir+'/{}'.format(img_fns[index])))\n",
    "    ax[i, 1].imshow(np.logical_or(pr_map == 0, pr_map == 1)) # live and injured\n",
    "    ax[i, 2].imshow(pr_map == 2)  # dead\n",
    "    ax[i, 3].imshow(pr_map ==3)   # background\n",
    "    if i == 0:\n",
    "        ax[i, 0].set_title('HeLa SLIM image')\n",
    "        ax[i, 1].set_title('Live')\n",
    "        ax[i, 2].set_title('Dead')\n",
    "        ax[i, 3].set_title('Background')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
